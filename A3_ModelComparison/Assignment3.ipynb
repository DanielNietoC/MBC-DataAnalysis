{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ibEsfuCyvJE"
   },
   "source": [
    "# Assignment 3\n",
    "## Statistical inference, bootstrap and model comparison\n",
    "\n",
    "**In this assignment, we will see how to compute bootstrapped confidence intervals and how to do model comparison.**\n",
    "\n",
    "- Learn how to use bootstrapping to generate new sample datasets\n",
    "- Estimate our model parameter on these new sample datasets\n",
    "- Quantify the variance of our estimate using confidence intervals\n",
    "\n",
    "- Parametric model comparison with AIC, BIC\n",
    "- Cross-validation for model selection\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "za5yFvk_yvJJ"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Preparing for this assignment:</b> \n",
    "\n",
    "The following resources will help you to get ready to complete this assignment. <br>\n",
    "Watch <a href=\"https://youtu.be/9JfXKmVB6qc?t=910\" target=\"_blank\">the second part of this video</a> to have a quick overview of how to assess model fits. Remember that all types of regression analysis and statistical test can be seen as testing how well a generative model (i.e. a linear model with noise) can explain your data. Then watch these series of short videos on more specific topics (all these videos are taken from the <a href=\"https://compneuro.neuromatch.io/tutorials/W1D2_ModelFitting/chapter_title.html\" target=\"_blank\">tutorials of the Model Fitting day at Neuromatch Academy</a>):\n",
    "        <li><a href=\"https://youtu.be/hs6bVGQNSIs\" target=\"_blank\">this video</a> on bootstrapping the estimate the confidence intervals for your model parameters</li>\n",
    "        <li> <a href=\"https://youtu.be/NcUH_seBcVw\" target=\"_blank\">this video</a> on the bias-variance trade-off, which provides the conceptual basis for model selection, i.e. finding a model that fits the data well while keeping model complexity as low as possible. For statistical analysis, this is equivalent to look for the significant effects as components that we must include in the model in order to capture the structure of the data.</li>\n",
    "        <li> <a href=\"https://youtu.be/OtKw0rSRxo4\" target=\"_blank\">this video</a> about how to perform model comparison in practice by testing the model on a test set (i.e. a part of the dataset that was not used for estimating the parameters), and how this is generalized in <b>cross-validation</b></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup\n",
    "\n",
    "We will keep working on the same example as in Assignment 2 (psychometric curves and logistic regression).\n",
    "\n",
    "We start by importing the typical libraries, importing the data as a dataframe and adding the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T22:27:37.824993Z",
     "start_time": "2022-02-09T22:27:36.401990Z"
    },
    "id": "2aF-qjnYk_2s"
   },
   "outputs": [],
   "source": [
    "#1. Load the packages that we will need\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# 2. load the data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/wimmerlab/MBC-DataAnalysis/main/A2_LogisticRegression/Experiment1_all_subjects.csv\")\n",
    "\n",
    "# 3. Define a function that takes two angles as input and outputs the angular distance between the two\n",
    "def circdist_deg(angles1,angles2): #define the name and set the arguments between parentheses\n",
    "    angle_diff = angles2 - angles1 # simple difference\n",
    "    angle_diff_rad = angle_diff*np.pi/180 # convert to radians\n",
    "    angular_dist_rad = np.angle( np.exp(1j*(angle_diff_rad))) ## mathematical operation to get the circular distance (in radians)\n",
    "    angular_dist = 180/np.pi*angular_dist_rad ## convert back to degrees\n",
    "    output = np.round(angular_dist) # round value to eliminate numerical imprecisions (all values are integer)\n",
    "    return output #return the circular distance in degrees \n",
    "\n",
    "# 4. Compute the displacement of the probe from the target and add it as a new column to the dataframe: \n",
    "df['displacement'] = circdist_deg( df['target'], df['probe'] );\n",
    "\n",
    "# 5. change the column 'response': all -1's become 1's and 1s become 0's\n",
    "df.response *= -1 # multiply by -1, so now 1 codes for CCW and -1 for CW\n",
    "df.loc[df.response==-1, 'response'] = 0 # convert -1s to 0s, so now 1 codes for CCW and 0 for CW\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper functions**\n",
    "\n",
    "There is nothing really new here as these functions were already used in Assignment 2. They are here to make your life easier. Have a look at what they are doing and use them in your code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic(x):\n",
    "    \"\"\"\n",
    "    Returns the output of the logistic function for the given input value (float or array-like).\n",
    "    \"\"\"\n",
    "    y = 1 / (1 + np.exp(-x))\n",
    "    return y\n",
    "\n",
    "def psychometric_model(d, w0, w1):\n",
    "    \"\"\"\n",
    "    Compute the psychometric function based on a simple logistic model. \n",
    "    Args:\n",
    "       d (ndarray): input values.\n",
    "       w0 (float): intercept for logistic regression.\n",
    "       w1 (float): slope for logistic regression.\n",
    "    Returns:\n",
    "       ndarray: The `y` data points of the psychometric function. \n",
    "          In our case, this corresponds to the probability of CCW responses.\n",
    "    \"\"\"\n",
    "    p = logistic(w0 + w1*d)\n",
    "    return p\n",
    "\n",
    "def plotcurve(df, color):\n",
    "    \"\"\"\n",
    "    Plot the fitted psychometric curve with experimental datapoints on top. \n",
    "    Args:\n",
    "       df (dataframe): experimental data\n",
    "       color (string): color of the datapoints and fitted line\n",
    "    \"\"\"\n",
    "\n",
    "    mod = smf.glm(formula='response ~ displacement', data=df, family=sm.families.Binomial())\n",
    "    res = mod.fit()\n",
    "    \n",
    "    myx = np.linspace(-20,20,100)\n",
    "    yfit=res.predict(pd.DataFrame({'displacement': myx})) #yfit = res.predict(exog={'probe_target':myx})\n",
    "\n",
    "    # plot the psychometric function (fit)\n",
    "    plt.plot(myx,yfit,'-', color=color,label='fit')\n",
    "    \n",
    "    # plot the psychometric curve (datapoints)\n",
    "    df.groupby('displacement').response.agg(('mean','sem')).plot(yerr='sem', color=color, fmt = 'o', ax=plt.gca(), label='data');\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show psychometric curve for subject 1**\n",
    "\n",
    "Your first task is to use the provided function `plotcurve` to plot the psychometric curve of subject 1.\n",
    "- Select the data of subject number 1\n",
    "- Use the pre-defined functions from above to plot the psychometric curve (datapoints and fit).\n",
    "\n",
    "*For parts 1 and 2 of this assignment, we will work with the data of this subject.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select subject 1\n",
    "ds = ??\n",
    "\n",
    "# plot the psychometric curve\n",
    "fig, ax = plt.subplots()\n",
    "??\n",
    "ax.set(xlabel='displacement (degrees)', ylabel='p(CCW)');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Bootstrapping\n",
    "\n",
    "[Bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) is a widely applicable method to assess confidence/uncertainty about estimated parameters, it was originally [proposed](https://projecteuclid.org/euclid.aos/1176344552) by [Bradley Efron](https://en.wikipedia.org/wiki/Bradley_Efron). The idea is to generate many new synthetic datasets from the initial true dataset by randomly sampling from it, then finding estimators for each one of these new datasets, and finally looking at the distribution of all these estimators to quantify our confidence.\n",
    "\n",
    "Note that each new resampled datasets will be the same size as our original one, with the new data points sampled with replacement i.e. we can repeat the same data point multiple times. Also note that in practice we need a lot of resampled datasets, here we use 2000.\n",
    "\n",
    "To explore this idea, we will work with the data from subject 1 and consider a simple logistic regression model for predicting the subject's responses from the angular displacement of the target and probe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Resample Dataset with Replacement\n",
    "\n",
    "In this exercise you will implement a method to resample a dataset with replacement. The method accepts $\\mathbf{x}$ and $\\mathbf{y}$ arrays. It should return a new set of $\\mathbf{x}'$ and $\\mathbf{y}'$ arrays that are created by randomly sampling from the originals.\n",
    "\n",
    "We will then compare the original dataset to a resampled dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** The [numpy.random.choice](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) method will be useful here. Before you start to implement the resampling function, first make sure that you understand the following two lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.choice(10, size=10, replace=False))\n",
    "print(np.random.choice(10, size=10, replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete the following function which we will use to generate the bootstrap samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resample_with_replacement(x, y):\n",
    "  \"\"\"Resample data points with replacement from the dataset of `x` inputs and\n",
    "  `y` measurements.\n",
    "  Args:\n",
    "    x (ndarray): An array of shape (samples,) that contains the input values.\n",
    "    y (ndarray): An array of shape (samples,) that contains the corresponding\n",
    "      measurement values to the inputs.\n",
    "  Returns:\n",
    "    ndarray, ndarray: The newly resampled `x` and `y` data points.\n",
    "  \"\"\"\n",
    "\n",
    "  # Get array of indices for resampled points\n",
    "  sample_idx = ??\n",
    "\n",
    "  # Sample from x and y according to sample_idx\n",
    "  x_ = ??\n",
    "  y_ = ??\n",
    "\n",
    "  return x_, y_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate resampled data and display the psychometric curves for the original and the resampled data.**\n",
    "\n",
    "Repeat this several times to get a feeling for the \"randomness\", that is how different the resampled data is from the original data.\n",
    "Note that `values` (in the first line) returns the numerical data contained in the dataframe (a numpy array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the data\n",
    "x_, y_ = resample_with_replacement(ds.displacement.values, ds.response.values)\n",
    "\n",
    "# place the resampled data in a dataframe\n",
    "ds_resampled = pd.DataFrame(??)\n",
    "\n",
    "# plot the psychometric curve\n",
    "fig, ax = plt.subplots()\n",
    "??\n",
    "??\n",
    "ax.set(xlabel='displacement (degrees)', ylabel='p(CCW)');\n",
    "plt.legend(('Original','Resampled'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to resample the data, we can use that in the full bootstrapping process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Bootstrap Estimates\n",
    "\n",
    "In this exercise you will implement a method to run the bootstrap process of generating a set of logistic regression weights $w_0$ and $w_1$ from a dataset of inputs ($\\mathbf{x}$, the displacement of target and probe) and  measurements ($\\mathbf{y}$, the subject's responses). You should use `resample_with_replacement` here.\n",
    "\n",
    "We will then use this function to look at the $w_0$ and $w_1$ values obtained from different samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm1FXeU1yvJb"
   },
   "source": [
    "First complete the following function that runs a simple logistic regression as in Assignment 2.\n",
    "Just as a reminder, we consider the influence onto our binary variable (choices) of a single variable: the displacement of the probe w.r.t the target stimulus (the parameter that controls the difficulty of the trial).\n",
    "Defining this function is useful because the only result that we want to store for the 2000 bootstrap samples are the values of the regression weights $w_0$ and $w_1$ and with the function our later code will be easier to read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T22:27:38.970245Z",
     "start_time": "2022-02-09T22:27:37.900143Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjkbo6dTk_3F",
    "outputId": "cfd0e3bb-7d82-46d1-b0b6-8ad09244e602"
   },
   "outputs": [],
   "source": [
    "# @markdown Execute this cell for helper function `solve_log_regression`\n",
    "def solve_log_regression(df):\n",
    "    \"\"\"Solve the logistic regression\n",
    "\n",
    "    Args:\n",
    "    df:dataframe\n",
    "\n",
    "  Returns:\n",
    "    two floats: the value for w0 and w1 for the fitted model\n",
    "    \"\"\"\n",
    "\n",
    "    # declare the logistic regression model\n",
    "    mod = smf.glm(??)\n",
    "\n",
    "    # fit the model\n",
    "    res = ??\n",
    "\n",
    "    return res.??, res.??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use your function to estimate the regression weights for the original data and the resampled data from above** (just to see if everything works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0,w1 = solve_log_regression(ds)\n",
    "print(\"original data:\")\n",
    "print(\"w_0 = \", w0,\"w_1 = \", w1)\n",
    "w0_resampled,w1_resampled = solve_log_regression(ds_resampled)\n",
    "print(\"resampled data:\")\n",
    "print(\"w_0 = \", w0_resampled,\"w_1 = \", w1_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj7o1xyxyvJg"
   },
   "source": [
    "**We are now ready to implement the bootstrap function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_estimates(x, y, n=2000):\n",
    "  \"\"\"Generate a set of theta_hat estimates using the bootstrap method.\n",
    "  Args:\n",
    "    x (ndarray): An array of shape (samples,) that contains the input values.\n",
    "    y (ndarray): An array of shape (samples,) that contains the corresponding\n",
    "      measurement values to the inputs.\n",
    "    n (int): The number of estimates to compute\n",
    "  Returns:\n",
    "    ndarray: An array of estimated parameters with size (n,2)\n",
    "  \"\"\"\n",
    "  theta_hats = np.zeros((n,2))\n",
    "\n",
    "  # Loop over number of estimates\n",
    "  for i in range(n):\n",
    "\n",
    "    # Resample x and y\n",
    "    x_, y_ = ??\n",
    "    df_resampled = ??\n",
    "\n",
    "    # Compute theta_hat for this sample\n",
    "    theta_hats[i,:] = solve_log_regression(??)\n",
    "\n",
    "  return theta_hats\n",
    "\n",
    "# For testing purposes we set the random seed so that we always get the same result\n",
    "np.random.seed(123)\n",
    "\n",
    "# Get bootstrap estimates (generate only 3 bootstrap samples for a quick check if everything works)\n",
    "theta_hats = bootstrap_estimates(ds.displacement.values, ds.response.values, n=3)\n",
    "\n",
    "# Now we initialize the random number generator so that we get different random numbers from now on.\n",
    "np.random.seed()\n",
    "\n",
    "print(theta_hats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see `[[0.34574091 0.12517866] [0.25904594 0.11718731] [0.05620029 0.14365177]]` as the first three estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our bootstrap estimates, we can visualize all the potential models (models computed with different resampling) together to see how distributed they are. Note that now we want to generate 2.000 bootstrap samples and fitting the corresponding logistic regression models can take a few seconds (depending on your machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = ??\n",
    "y = ??\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Generate bootstrap samples and fits\n",
    "theta_hats = bootstrap_estimates(??)\n",
    "\n",
    "# For each theta_hat, plot model\n",
    "myx = np.linspace(-20,20,100)\n",
    "for i, theta_hat in enumerate(theta_hats):\n",
    "  y_hat = psychometric_model(myx, theta_hat[0], theta_hat[1])\n",
    "  ax.plot(myx, y_hat, c='r', alpha=0.01, label='Resampled Fits' if i==0 else '')\n",
    "\n",
    "# Plot observed data\n",
    "??\n",
    "\n",
    "ax.set(\n",
    "  title='Bootstrapped Parameter Estimation',\n",
    "  xlabel='x',\n",
    "  ylabel='y'\n",
    ")\n",
    "\n",
    "# Change legend line alpha property\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "handles[0].set_alpha(1)\n",
    "\n",
    "ax.legend();\n",
    "\n",
    "# we add a vertical line at d=0 (i.e. when the target is at the same angle as the probe)\n",
    "plt.axvline(x = 0, color = 'k', linestyle = '--')\n",
    "\n",
    "#and horizontal line a pCCW = 0.5 (i.e. equal probability of CW and CCW responses)\n",
    "plt.axhline(y = 0.5, color = 'k', linestyle = '--');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good! The bootstrapped estimates spread around the observed datapoints, as we would have hoped.  As always it is a good idea to visually inspect the quality of estimates.\n",
    "Now you can try to run the bootstrap procedure on all the subjects together (just taking all the data, ignoring the subject identity). **What happens to the spread of the bootstrap estimates? (insert your answer below)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Confidence Intervals\n",
    "\n",
    "Let us now quantify how uncertain our estimated parameters ($w_0$ and $w_1$) is. We do so by computing [confidence intervals](https://en.wikipedia.org/wiki/Confidence_interval) (CIs) from our bootstrapped estimates. The most direct approach is to compute percentiles from the empirical distribution of bootstrapped estimates. Note that this is widely applicable as we are not assuming that this empirical distribution is Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Plot bootstrap samples and confidence intervals\n",
    "\n",
    "**Hint**: you can use `np.percentile`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run the analysis for all subjects, uncomment the following 3 lines\n",
    "#x = df.displacement.values\n",
    "#y = df.response.values\n",
    "#theta_hats = bootstrap_estimates(x, y, n=2000)\n",
    "\n",
    "means = np.mean(theta_hats,axis=0)\n",
    "stds = np.std(theta_hats,axis=0)\n",
    "medians = ??\n",
    "CIs = ??\n",
    "\n",
    "# insert below your code that displays two histograms (one for the bootstrap samples of $w_0$ \n",
    "# and one for the bootstrap samples of $w_1$)\n",
    "# display vertical lines to indicate the confidence interval and the original data\n",
    "\n",
    "??\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are the responses of this subjects biased?** (Hint: the bias is reflected in $\\hat{w_0}$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<< add your answer here >>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good idea to **repeat the analysis with a different subject or with all subjects pooled together** in order to get a better intuition about the datapoints, fitted psychometric curve and confidence intervals for the fitted parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Comparison with confidence intervals obtained by Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compare the confidence intervals obtained using bootstrap with the confidence intervals reported by `sm.glm`.\n",
    "Also compare the standard deviation of the bootstrapped parameter estimates to the std err reported by `sm.glm`.\n",
    "\n",
    "Note that the code below uses [f-Strings](https://realpython.com/python-f-strings/#f-strings-a-new-and-improved-way-to-format-strings-in-python), a convinient way of displaying numbers with a certain format (e.g. number of digits after the comma). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"                   mean      std        [0.025      0.975]\")\n",
    "print(f\"----------------------------------------------------------\")\n",
    "print(f\"w0               {means[0]:.4f}      {stds[0]:.3f}       {CIs[0,0]:.3f}       {CIs[1,0]:.3f}\")\n",
    "print(f\"w1               {means[1]:.4f}      {stds[1]:.3f}       {CIs[0,1]:.3f}       {CIs[1,1]:.3f}\")\n",
    "print(f\"==========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the logistic regression model\n",
    "mod = smf.glm(formula= 'response ~ displacement' , data = ds, family = sm.families.Binomial() )\n",
    "\n",
    "# fit the model\n",
    "res = mod.fit()\n",
    "\n",
    "# print results as a summary table\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss your results below:**\n",
    "\n",
    "**Optional question: what is the relationship between the standard error of the mean (sem) and the standard deviation of the bootstrap samples?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<< your answer here >>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary of bootstrapping\n",
    "\n",
    "- Bootstrapping is a resampling procedure that allows to build confidence intervals around inferred parameter values\n",
    "- it is a widely applicable and very practical method that relies on computational power and pseudo-random number generators (as opposed to more classical approaches than depend on analytical derivations)\n",
    "- is non-parametric: the confidence intervals provided by statistical libraries are not always accurate because they assume an underlying gaussian distribution for parameters, which is not always the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model comparison using penalized likelihood\n",
    "In traditional statistics, we test the presence of an effect in the data by assessing if it is credible that the effect is absent, i.e. whether the null hypothesis (the absence of the effect) can be rejected. This is what we have done in the previous section, we tested whether a null value for the regression weights is plausible. But the validity of the alternative hypothesis is never tested directly.\n",
    "\n",
    "Now, using the framework of statistical modelling offers a richer set of tools because we can **directly compare the null hypothesis and the alternative hypothesis** and assess which one better accounts for the experimental data. The approach is even more generic: the tools of statistical modelling / machine learning allows to directly compare any statistical models based on some dataset.\n",
    "\n",
    "In previous assignments, we have seen two metrics that assess how well a model captures the data:\n",
    "- the mean-squared error, in the case of linear regression (the smaller the better)\n",
    "- the (log-)likelihood, which can be used in all settings (the larger the better). Remember that the maximum-likelihood approach is actually equivalent to the minimum-squared error for linear regression, but works in other cases.\n",
    "We have used these two metrics to decide, given a certain parametric model of the data (i.e. linear regression), which set of parameters better describe the data. But the same philosophy can be used to decide which of two different models better describes the data: the larger the likelihood, the better the model.\n",
    "\n",
    "Yet there is a caveat. The likelihood is usually estimated for each model at the maximum-likelihood parameters. But if a certain model has more parameters, then there is larger space of parameters to maximize the likelihood, i.e. the model is more flexible, so it will receive an unfair advantage when comparing the likelihoods with other models. Even if those extra parameters do not contribute anything to capturing the true processes that underlie the generation of the data, giving this extra-flexibility can allow it to improve the likelihood simply by adjusting to noise. This is the problem of **overfitting**. In the videos, we have seen that we need to find a right balance between fitting the data and model parsimony, what is know as the **bias-variance trade-off**. \n",
    "\n",
    "To make the comparison more fair between models of different complexities, one approach is simply to apply a certain penalty term on top of the likelihood that penalizes the models with more parameters. The two most popular metrics for doing so just differ in the strength of the penalty term: \n",
    "- the **Akaike Information Criterion (AIC)** is computed as $AIC = 2k - 2 \\hat{LLH}$, where $k$ is the number of parameters of the model (i.e. a simple linear regression model will have two, the intercept and the slope) and $\\hat{LLH}$ is the log-likelihood of the model estimated at the maximum-likelihood parameters (the value that is provided in the summary of the model after fitting).\n",
    "- the **Bayesian Information Criterion (BIC)** is computed as $BIC = k \\log n - 2 \\hat{LLH}$ where $n$ is the number of observations (i.e. trials).\n",
    "The smaller the AIC (or BIC), the better is the model, because of the negative sign before the log-likelihood. The first part of the equation is positive and correspond to the penalty term. That term is larger in the case of the BIC, i.e. the BIC penalizes more severely models with many parameters than the AIC. In other words, it will be more conservative in rejecting the null hypothesis. It's important to note that these are **relative measures**: their raw values tell us very little, it's only by comparing values between different models that we can interpret which model better captures the data. So we cannot conclude from the BIC/AIC that one model is a good model of the data; only that it is a better model of the data than others. \n",
    "\n",
    "Akaike's rule of thumb: **two models are essentially indistinguishable if the difference of their AICs is less than 2** (same for BIC). The larger the difference, the more evidence towards the better model against the other.\n",
    "\n",
    "But enough talking, let's see how to apply this in practice. We will look back to the analysis that suggests that, in memory trials, the relative position distractor has an impact on the choice of the participants.\n",
    "\n",
    "First, fit a **logistic regression model with probe displacement and distance of the distractor as regressors, restricting the analysis to memory trials** (i.e. delay of 1s or 3s). \n",
    "Unlike what we did in the previous assignment where we analyzed data from all subjects together without taking into account the population heterogeneity, the good practice is to apply statisical modelling on a single-subject data (or used mixed-effects models as we saw in Assignment 2B). Here we will **work on on the data for one subject only: subject 5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Compute the distance between the distractor and the target and add as a new column to the dataframe:\n",
    "df['dist_distractor'] = circdist_deg( df['target'] , df['near'] )\n",
    "\n",
    "# we restrict the dataframe to memory trials and trials from subject 5\n",
    "memory_trials_subject5 =  ??\n",
    "\n",
    "# dataframe for memory trials and subject 5\n",
    "df_memory = ??\n",
    "\n",
    "# when we take a subset of a dataframe, the indices reflect the position of the selected rows in the old dataset. \n",
    "# We use reset_index to reset the indices, i.e. going back as 1, 2, ... (this avoids frequent error afterwards)\n",
    "df_memory = df_memory.reset_index(drop=True)\n",
    "\n",
    "# declare the logistic regression model\n",
    "??\n",
    "\n",
    "# fit the model\n",
    "??\n",
    "\n",
    "# print results as a summary table\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to compare this model to the null model, which is exactly the same but where the influence of the distractor is removed. **Fit the null model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first **compare the log-likelihood of both models**. This value (provided in the summary) is given by `res.llf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LLH for the model with distractor: \" + str(??))\n",
    "print(\"LLH for the null model: \" + str(??))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you observe? Is it expected?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) The value of the AIC is directly provided by `statsmodel` as `res.aic`.\n",
    "**Check that the value corresponds to the formula provided above** (the list of parameters of the model is given by `res.params`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC\n",
    "print(res.aic)\n",
    "\n",
    "# Use the formula\n",
    "nParam = ??\n",
    "print(??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now **compare the AIC from the two models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the BIC from the two models** (use  `res.bic_llf`, not `res.bic`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Optional)** Now run the analyses again with subject 3. What do you conclude for this subject?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing model performance on held out data\n",
    "The AIC and BIC are convenient because they are easy to compute, but they are just \"approximately good\". For large sample size, they work well, but for smaller sample size they may not accurately describe which model is better. Moreover, as we have seen, they sometimes provide contradictory results, which is always frustrating.\n",
    "\n",
    "Another approach for comparing models on experimental data while adjusting for model complexity is to test the model performance on datapoints that have not been used to train/fit the model (i.e. estimated the maximum-likelihood parameters). If a model with many parameters is overfitting, i.e. its parameters are adjusted to predict very well the datapoints it was trained on (it is fitting 'noise'), then its performance may decrease severely when testing the model with the same parameters but on a new dataset. \n",
    "How this is done in practice is that we **split our datasets into two smaller datasets**: one **training set** which is used to fit the model and extract the maximum-likelihood parameters, and one **test set** (or held-out data) which is used to evaluate the performance of the model previously fitted. This method naturally corrects for model complexity when comparing different models. Let us do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to divide our dataset in two. In general the training set is the larger, usually taking 80% of the data, while the test set takes the remaining 20%.\n",
    "This can be done using `train_test_split` from `statsmodel`, which randomly assign each observation to either the train or test set, while controlling for the relative size of each set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# make sure to use again data for subject 5!\n",
    "???\n",
    "\n",
    "# when we take a subset of a dataframe, the indices reflect the position of the selected rows in the old dataset. \n",
    "# We use reset_index to reset the indices, i.e. going back as 1, 2, ... (this avoids frequent error afterwards)\n",
    "df_memory = df_memory.reset_index(drop=True)\n",
    "\n",
    "# create two dataframes. Parameter test_size (between 0 and 1) controls the relative size of the test set.\n",
    "df_train, df_test = train_test_split(??, test_size=??)\n",
    "\n",
    "# when we take a subset of a dataframe, the indices reflect the position of the selected rows in the old dataset. \n",
    "# We use reset_index to reset the indices, i.e. going back as 1, 2, ... (this avoids frequent error afterwards)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size (number of rows) of the train and test sets. Check how this is affected by changing the `test_size` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were to sample the data \"manually\" to split between the train and test sets (instead of using `train_test_split`), would you set the `replace` option of `np.random.choice` to `True` or `False`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's follow the procedure:\n",
    "- **fit both models (with or without distractor regressor) to the train set**\n",
    "- **use the fitted models to generate predictions for the probability of CCW response on the test set**. (Remember we in Assignment 2B we saw how to use `res.predict`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with impact of distractor on training set\n",
    "???\n",
    "\n",
    "# fit null model on training set\n",
    "???\n",
    "\n",
    "# use the fitted statistical model to compute p(CCW) for each value in this dataframe\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a prediction for each trial in the test set, and what we want is a single metric, the LogLikelihood on the test data, to compare the models. There are no built-in method in `statsmodel` for computing the log-likelihood on test data, so we use the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute likelihood of test data\n",
    "def loglikelihood_binary(pModel, resp):\n",
    "    \"\"\"Computes the log-likelihood of binary dataset for a given model.\n",
    "  Args:\n",
    "    pModel (ndarray): An array of shape (samples,) that contains the probability \n",
    "    of response 1 according to the model\n",
    "    resp (ndarray): An array of shape (samples,) that contains the binary data\n",
    "  Returns:\n",
    "    LLH: the log-likelihood of the model\n",
    "  \"\"\"\n",
    "    \n",
    "    # number of observations / trials\n",
    "    n = len(pModel)\n",
    "    \n",
    "    # initialize log-likelihood\n",
    "    LLH = 0\n",
    "    \n",
    "    # loop through trials\n",
    "    for i in range(n):\n",
    "        \n",
    "        if (resp.iloc[i]==1):\n",
    "            lh = pModel.iloc[i]\n",
    "        else:\n",
    "            lh = 1-pModel.iloc[i]\n",
    "            \n",
    "        # add logarithm of likelihood for the trial to LLH\n",
    "        LLH += np.log(lh)\n",
    "        \n",
    "    return LLH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to **compute the log-likelihood of both models on the test data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "????\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Crossvalidation\n",
    "\n",
    "\n",
    "That is good, but if you run the analysis again, you will notice that the results vary every time. This is because everytime you run the analysis, you generate a new random split of the dataset between the train and test sets. Obviously, our measure of which model is best should not depend on a random generator! One way of dealing with this is to perform various splitting, compute the test score for each split, and then average over splittings. The more splittings we perform, the more robust our measure will be. This is usually done using **cross-validation**, where the dataset is chunked in pieces (or folds), where each piece alternatively takes the role of the test set. The most standard form of cross-validation is K-fold cross-validation, where K describes the number of folds in which the data is split. This is illustrated below using $K=5$. The log-likelihood of cross-validated data is described as \"Cross-Validated Log-Likelihood\" (**CVLL**).\n",
    "\n",
    "In general, the larger is K, the more robust your measure is. The extreme case is **leave-one-out cross-validation** (LOOCV) where basically you split the datasets in sets of just one observation (trials); then on each fold you fit all your dataset on all the dataset but one observation and test it on this single heldout observation. So LOOCV is like K-fold CV where K equals the number of observations. However, by increasing K, you also increase the computational complexity as you need to fit the model over and over, so things can get slow.\n",
    "\n",
    "Cross-validation is a robust method for choosing the best statistical model for a certain dataset. It does not suffer the same limitations as AIC/BIC, and can be used for other metrics than the log-likelihood such as the mean squared error or the classification accuracy. This it can be used also for complex methods when the likelihood cannot be evaluated.\n",
    "This is why **cross-validation is the standard method in machine learning** to compare the performance of any type of models (deep networks, auto-encoders, SVMs, etc.).\n",
    "\n",
    "(Image taken from [https://www.askpython.com/python/examples/k-fold-cross-validation])"
   ]
  },
  {
   "attachments": {
    "5-Fold-Cross-Validation.jpg.webp": {
     "image/webp": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5-Fold-Cross-Validation.jpg.webp](attachment:5-Fold-Cross-Validation.jpg.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we split the data into 10 subsets using `Kfold` (from `sklearn.model_selection`). `KFold` handles cross-validation subset splitting and train/val assignments.  In particular, the `Kfold.split` method returns an iterator which we can loop through. On each loop, this iterator assigns a different subset as validation and returns new training and validation indices with which to split the data. \n",
    "\n",
    "We will loop through the 10 train/validation splits and on each split compute the log-likelihood of both models on the test set. Then we will average the CVLL over splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# number of folds\n",
    "K = ??\n",
    "\n",
    "#create Kfold object\n",
    "kf = KFold(n_splits = K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply K-fold validation on the dataset to compute the CVLL on both the distractor and null models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CVLL as numpy array with K rows and 2 columns, one for each model\n",
    "CVLL_all = ??\n",
    "\n",
    "# loop through all folds (the complex syntax provides the loop counter i, as well as the indices of trials in train and test sets for the corresponding fold)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df_memory)):\n",
    "    \n",
    "    # dataframe with training data\n",
    "    df_train = ??\n",
    "    \n",
    "    # dataframe with test data\n",
    "    df_test = ??\n",
    "       \n",
    "    # fit model with impact of distractor on training set\n",
    "    ???\n",
    "\n",
    "    # fit null model on training set\n",
    "       ??\n",
    "\n",
    "    # use the fitted statistical model to compute p(CCW) for each value in this dataframe\n",
    "    ??\n",
    "    \n",
    "    # compute the CVLL for each model\n",
    "    LLH_test = ??\n",
    "    LLH_test_null = ??\n",
    "    \n",
    "    # add as row in array\n",
    "    CVLL_all[i] = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the difference in CVLL between the distractor model and the null model on each fold** (use a bar plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the difference of CVLL between the two models on each fold\n",
    "CVLL_diff = ??\n",
    "\n",
    "# Plot as bar plot\n",
    "??\n",
    "\n",
    "# Add axis labels\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the average difference of CVLL across folds.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you conclude?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "assignment5.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
